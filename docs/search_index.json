[
["vector-space-representation-ii.html", "Chapter 11 Vector Space Representation II 11.1 Loading the Corpus 11.2 Semgentation 11.3 Corpus Metadata 11.4 Document-Feature Matrix 11.5 Wordcloud 11.6 Document Similarity 11.7 Feature Similarity", " Chapter 11 Vector Space Representation II library(tidyverse) library(quanteda) library(readtext) library(jiebaR) Figure 11.1: Corpus Processing Flowchart In Chapter 10, we demonstrate the potential of a vector representation of documents with the English data. Here, we would like to look at the Chinese data in a more detail. In the corpus data processing flowchart, as repeated below, we need to deal with the word segmentation with the Chinese data. This prevents us from creating a dfm directly from a corpus object because the default internal word tokenization in quanteda is not optimized for non-English languages. In this chapter, we will be using the dataset TaiwanPresidentalSpeech.zip in our demo_data directory. Please make sure that you have downloaded the dataset. 11.1 Loading the Corpus corp_tw &lt;- readtext(file=&quot;demo_data/TW_President.tar.gz&quot;) %&gt;% as_tibble corp_tw %&gt;% mutate(text = str_sub(text, 1,20)) 11.2 Semgentation # initialize segmenter chi_seg &lt;- worker(bylines = T, user = &quot;demo_data/dict-ch-user.txt&quot;) corp_tw_tokens &lt;- corp_tw$text %&gt;% segment(jiebar = chi_seg) %&gt;% as.tokens corp_tw_tokens$text14[1:10] ## [1] &quot;為&quot; &quot;年輕人&quot; &quot;打造&quot; &quot;一個&quot; &quot;更好&quot; &quot;的&quot; &quot;國家&quot; &quot;各位&quot; ## [9] &quot;友邦&quot; &quot;的&quot; 11.3 Corpus Metadata corp_tw_meta &lt;-corp_tw %&gt;% dplyr::select(-text) %&gt;% separate(doc_id, into = c(&quot;YEAR&quot;,&quot;TERM&quot;,&quot;PRESIDENT&quot;),sep = &quot;_&quot;) %&gt;% mutate(PRESIDENT = str_replace(PRESIDENT, &quot;.txt&quot;,&quot;&quot;)) docvars(corp_tw_tokens) &lt;- corp_tw_meta 11.4 Document-Feature Matrix corp_tw_dfm &lt;- corp_tw_tokens %&gt;% dfm(reove_punc = T) %&gt;% dfm_trim(min_termfreq = 10, termfreq_type = &quot;count&quot;, min_docfreq = 2, max_docfreq = 10, docfreq_type = &quot;count&quot;) corp_tw_dfm[1:5, 1:10] ## Document-feature matrix of: 5 documents, 10 features (32.0% sparse). ## 5 x 10 sparse Matrix of class &quot;dfm&quot; ## features ## docs 中正 國民大會 國父 環境 以及 到 以來 知道 自己 此 ## text1 5 1 3 2 2 1 1 2 1 2 ## text2 4 4 1 1 2 2 0 3 0 0 ## text3 5 1 1 0 0 5 0 4 4 0 ## text4 7 3 7 0 0 0 1 1 2 1 ## text5 5 1 1 0 0 0 0 0 0 3 11.5 Wordcloud require(wordcloud2) require(wordcloud) top_features &lt;- corp_tw_dfm %&gt;% topfeatures(100) word_freq &lt;- data.frame(word = names(top_features), freq = top_features) word_freq %&gt;% wordcloud2() 11.6 Document Similarity corp_tw_dist &lt;- corp_tw_dfm %&gt;% dfm_weight(scheme = &quot;prop&quot;) %&gt;% textstat_dist corp_tw_hist &lt;- corp_tw_dist %&gt;% as.dist %&gt;% hclust hist_labels &lt;- str_c(docvars(corp_tw_dfm,&quot;PRESIDENT&quot;), docvars(corp_tw_dfm,&quot;YEAR&quot;), sep=&quot;_&quot;) plot(corp_tw_hist, hang = -1, cex = 1.2, label = docvars(corp_tw_dfm,&quot;PRESIDENT&quot;)) 11.7 Feature Similarity # convert `dfm` to `fcm` corp_tw_fcm &lt;- corp_tw_dfm %&gt;% fcm # select top 30 features corp_tw_topfeatures &lt;- names(topfeatures(corp_tw_fcm, 50)) # plot network library(showtext) font_add(&quot;Arial Unicode MS&quot;, &quot;Arial Unicode.ttf&quot;) ## Automatically use showtext to render plots showtext_auto(enable = TRUE) #par(family = &quot;Arial Unicode MS&quot;) fcm_select(corp_tw_fcm, pattern = corp_tw_topfeatures) %&gt;% textplot_network(min_freq = 0.5) -&gt;g ggsave(&quot;test.png&quot;, g) Exercise 11.1 Create the network of top 30 bigrams for the corpus corp_tw. The critera for bigrams selection are as follows: include bigrams whose frequency &gt;= 10 and docfreq &gt;=5 "]
]
