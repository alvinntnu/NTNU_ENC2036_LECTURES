[
["xml.html", "Chapter 12 XML 12.1 BNC Spoken 2014 12.2 Process the Whole Directory of BNC2014 Sample 12.3 Metadata 12.4 BNC2014 for Socialinguistic Variation 12.5 Lexical Analysis 12.6 Constructions Analysis", " Chapter 12 XML library(tidyverse) library(readtext) library(rvest) library(tidytext) library(quanteda) This chapter shows you how to process the recently released BNC 2014, which is by far the largest representative collection of spoken English collected in UK. For the purpose of our in-class tutorials, I have included a small sample of the BNC2014 in our demo_data. However, the whole dataset is now available via the official website: British National Corpus 2014. Please sign up for the complete access to the corpus if you need this corpus for your own research. 12.1 BNC Spoken 2014 XML is similar to HTML. Before you process the data, you need to understand the structure of the XML tags in the files. Usually we would start from the documentation of the corpus. Please read The BNC 2014: User Manual amd Reference Guide for more detail. Other than that, the steps are pretty much similar to what we have learned before. First, we read the XML using read_html(): # read one file at a time corp_bnc&lt;-read_html(&quot;demo_data/corp-bnc-spoken2014-sample/S2A5-tgd.xml&quot;) Now it is intuitive that our next step is to extract all utterances (with the tag of &lt;u&gt;...&lt;/u&gt;) in the XML file. So you may want to do the following: corp_bnc %&gt;% html_nodes(xpath = &quot;//u&quot;) %&gt;% html_text %&gt;% head ## [1] &quot;\\r\\nanhourlaterhopeshestaysdownratherlate&quot; ## [2] &quot;\\r\\nwellshehadthosetwohoursearlier&quot; ## [3] &quot;\\r\\nyeahIknowbutthat&#39;swhywe&#39;reanhourlateisn&#39;tit?mmI&#39;mtirednow&quot; ## [4] &quot;\\r\\n&quot; ## [5] &quot;\\r\\ndidyoutext--ANONnameM&quot; ## [6] &quot;\\r\\nyeahyeahhewrotebacknobotherlad&quot; See the problem? Using the above method, you lose the word boundary information from the corpus. What if you do the following? corp_bnc %&gt;% html_nodes(xpath = &quot;//w&quot;) %&gt;% html_text %&gt;% head(20) ## [1] &quot;an&quot; &quot;hour&quot; &quot;later&quot; &quot;hope&quot; &quot;she&quot; &quot;stays&quot; &quot;down&quot; ## [8] &quot;rather&quot; &quot;late&quot; &quot;well&quot; &quot;she&quot; &quot;had&quot; &quot;those&quot; &quot;two&quot; ## [15] &quot;hours&quot; &quot;earlier&quot; &quot;yeah&quot; &quot;I&quot; &quot;know&quot; &quot;but&quot; At the first sight, probably it seems that we have solved the problem but we don’t. There are even more problems created: Our second method does not extract non-word tokens within each utterance (e.g., &lt;pause .../&gt;, &lt;vocal .../&gt;) Our second method loses the utterance information (i.e., we don’t know which utterance each word belongs to) So we cannot extract &lt;u&gt; elements all at once; nor can we extract all &lt;w&gt; elements all at once. Probably we need to process each &lt;u&gt; node one at a time. First, let’s get all the &lt;u&gt; nodes. node_u &lt;- corp_bnc %&gt;% html_nodes(xpath=&quot;//u&quot;) node_u[[1]] ## {html_node} ## &lt;u n=&quot;1&quot; who=&quot;S0024&quot; trans=&quot;nonoverlap&quot; whoconfidence=&quot;high&quot;&gt; ## [1] &lt;w pos=&quot;AT1&quot; lemma=&quot;a&quot; class=&quot;ART&quot; usas=&quot;Z5&quot;&gt;an&lt;/w&gt; ## [2] &lt;w pos=&quot;NNT1&quot; lemma=&quot;hour&quot; class=&quot;SUBST&quot; usas=&quot;T1:3&quot;&gt;hour&lt;/w&gt; ## [3] &lt;w pos=&quot;RRR&quot; lemma=&quot;later&quot; class=&quot;ADV&quot; usas=&quot;T4&quot;&gt;later&lt;/w&gt; ## [4] &lt;pause dur=&quot;short&quot;&gt;&lt;/pause&gt; ## [5] &lt;w pos=&quot;VV0&quot; lemma=&quot;hope&quot; class=&quot;VERB&quot; usas=&quot;X2:6&quot;&gt;hope&lt;/w&gt; ## [6] &lt;w pos=&quot;PPHS1&quot; lemma=&quot;she&quot; class=&quot;PRON&quot; usas=&quot;Z8&quot;&gt;she&lt;/w&gt; ## [7] &lt;w pos=&quot;VVZ&quot; lemma=&quot;stay&quot; class=&quot;VERB&quot; usas=&quot;M8&quot;&gt;stays&lt;/w&gt; ## [8] &lt;w pos=&quot;RP&quot; lemma=&quot;down&quot; class=&quot;ADV&quot; usas=&quot;Z5&quot;&gt;down&lt;/w&gt; ## [9] &lt;pause dur=&quot;short&quot;&gt;&lt;/pause&gt; ## [10] &lt;w pos=&quot;RG&quot; lemma=&quot;rather&quot; class=&quot;ADV&quot; usas=&quot;A13:5&quot;&gt;rather&lt;/w&gt; ## [11] &lt;w pos=&quot;JJ&quot; lemma=&quot;late&quot; class=&quot;ADJ&quot; usas=&quot;T4&quot;&gt;late&lt;/w&gt; Take the first node in the XML document for example, each utterance node includes words as well as non-word tokens (i.e., paralinguistic annotations &lt;pause ...&gt;&lt;/pause&gt;). We can retrieve: words in an utterance lemma forms of all words in the utterance pos tags of all words in the utterance (BNC2014 uses UCREL CLAWS6 Tagset) paralinguistic tags in the utterance node_u[[1]] %&gt;% html_children %&gt;% html_text ## [1] &quot;an&quot; &quot;hour&quot; &quot;later&quot; &quot;&quot; &quot;hope&quot; &quot;she&quot; &quot;stays&quot; &quot;down&quot; ## [9] &quot;&quot; &quot;rather&quot; &quot;late&quot; node_u[[1]] %&gt;% html_children %&gt;% html_attr(&quot;pos&quot;) ## [1] &quot;AT1&quot; &quot;NNT1&quot; &quot;RRR&quot; NA &quot;VV0&quot; &quot;PPHS1&quot; &quot;VVZ&quot; &quot;RP&quot; NA ## [10] &quot;RG&quot; &quot;JJ&quot; node_u[[1]] %&gt;% html_children %&gt;% html_attr(&quot;lemma&quot;) ## [1] &quot;a&quot; &quot;hour&quot; &quot;later&quot; NA &quot;hope&quot; &quot;she&quot; &quot;stay&quot; &quot;down&quot; ## [9] NA &quot;rather&quot; &quot;late&quot; In the above extraction of words, parts-of-speech tags, and lemma forms of each word token in the utterance, there are NA’s in the return. Do you know why? For each utterance, the XML file provides also the metadata information for each utterance, including: its unique index (n) speaker id (who) transition type (trans, i.e., whether or not the transition between turns was overlapping) attribution confidence (whoconfidence, whether or not the transcriber was confident that they had correctly identified the speaker of the turn) node_u[[1]] %&gt;% html_attrs() ## n who trans whoconfidence ## &quot;1&quot; &quot;S0024&quot; &quot;nonoverlap&quot; &quot;high&quot; Exercise 12.1 Now we know how to extract token-level information and utterance-level annotation from each utterance. Please come up with a way to extract all relevant linguistic data from all utterances in the file S2A5-tgd.xml, including their word and non-word tokens as well as their metadata. Ideally, the resulting data frame should consist of rows being the tokens of the utterances, and columns including the attributes and strings of each token. Most importantly, the data frame should include not only the strings of the tokens, but at the same time for the word tokens, it should preserve the BNC token-level annotations of part-of-speech tags, lemmas, and semantic tags (i.e., usas). Also, each token is connected to the utterance-level metadata, such as the utterance ID, speaker ID etc. A sample utterance-based data frame is provided below. 12.2 Process the Whole Directory of BNC2014 Sample 12.2.1 Define Function In Section 12.1, if you have figured how to extract the token-based data frame from all utterances in an XML file, you can easily wrap the whole procedure as one function. With this function, we can perform the same procedure to all the xml files of the BNC2014. For example, let’s assume that we have defined a function: read_xml_bnc2014 &lt;- function(xml){ ... ... ... } # endfunc This function takes one xml file as an argument and return a token-based data frame, consisting of token texts and other relevant utteracne-level and token-level information from the xml. word_df &lt;- read_xml_bnc2014(xmlfile = &quot;demo_data/corp-bnc-spoken2014-sample/S2A5-tgd.xml&quot;) word_df %&gt;% filter(n %in% c(&quot;1&quot;,&quot;2&quot;)) Exercise 12.2 Now your job is to create this function, read_xml_bnc2014(xmlfile = &quot;&quot;). The function should take the path to one XML file as the input and return a token-based data frame of the XML file as shown above. 12.2.2 Process the all files in the Directory Now we can utilize the self-defined function, read_xml_bnc2014(), and process all xml files in the demo_data/corp-bnc-spoken2014-sample/. Also, we combine the individual data.frame returned from each XML into a bigger one, i.e., corp_bnc_df: # file list bnc_flist &lt;- dir(&quot;demo_data/corp-bnc-spoken2014-sample/&quot;,full.names = T) # extract token-based df system.time(corp_bnc_list &lt;- lapply(bnc_flist, read_xml_bnc2014)) # combine all df&#39;s corp_bnc_token_df &lt;- corp_bnc_list %&gt;% do.call(rbind, .) %&gt;% mutate(xml_id = rep(basename(bnc_flist), sapply(corp_bnc_list,nrow))) # save file write_csv(corp_bnc__token_df, path= &quot;demo_data/data-corp-token-bnc2014.csv&quot;) It takes a while to process/parse all the files included in the sample directory because we parse the entire XML file and extract almost everything from the file. You may store this corp_bnc_token_df data frame output for later use so that you don’t have to process the XML files every time you work with BNC2014. The parsed token-based data frame of the BNC2014 is available in our demo_data/data-corp-token-bnc2014.csv: corp_bnc_token_df &lt;- read_csv(&quot;demo_data/data-corp-token-bnc2014.csv&quot;) corp_bnc_token_df %&gt;% filter(xml_id == &quot;S2A5-tgd.xml&quot; &amp; n == &quot;1&quot;) 12.3 Metadata The best thing about BNC2014 is its rich demographic information relating to the settings and speakers of the conversations collected. The whole corpus comes with two metadata sets: bnc2014spoken-textdata.tsv: metadata for each text transcript bnc2014spoken-speakerdata.tsv: metadata for each speaker ID These two metadata sets allow us to get more information about each transcript as well as the speakers in those transcripts. 12.3.1 Text Metadata There are two files that are relevant to the text metadata: bnc2014spoken-textdata.tsv: This file includes the header/metadata information of each text file metadata-fields-text.txt: This file includes the column names/meanings of the previous text metadata tsv, i.e., bnc2014spoken-textdata.tsv. bnc_text_meta &lt;- read_tsv(&quot;demo_data/corp-bnc-spoken2014-metadata/bnc2014spoken-textdata.tsv&quot;, col_names = FALSE) bnc_text_meta bnc_text_meta_names &lt;-read_tsv(&quot;demo_data/corp-bnc-spoken2014-metadata/metadata-fields-text.txt&quot;, skip =2, col_names = F) bnc_text_meta_names names(bnc_text_meta) &lt;- c(&quot;textid&quot;, bnc_text_meta_names$X2) bnc_text_meta 12.3.2 Speaker Metadata There are two files that are relevant to the speaker metadata: bnc2014spoken-speakerdata.tsv: This file includes the demographic information of each speaker metadata-fields-speaker.txt: This file includes the column names/meanings of the previous speaker metadata tsv, i.e., bnc2014spoken-speakerdata.tsv. bnc_sp_meta &lt;- read_tsv(&quot;demo_data/corp-bnc-spoken2014-metadata/bnc2014spoken-speakerdata.tsv&quot;, col_names = F) bnc_sp_meta bnc_sp_meta_names &lt;- read_tsv(&quot;demo_data/corp-bnc-spoken2014-metadata/metadata-fields-speaker.txt&quot;, skip = 3, col_names = F) bnc_sp_meta_names names(bnc_sp_meta) &lt;- c(&quot;spid&quot;, bnc_sp_meta_names$X2) bnc_sp_meta 12.4 BNC2014 for Socialinguistic Variation Now with both the text-level and speker-level metadata, bnc_text_meta and bnc_sp_meta, we can easily connect the utterances to speaker and text profiles using their unique ID’s. BNC2014 was born for the study of socio-linguistic variation. Here I would like to show you some naitve examples, but you should get the ideas and the potentials of BNC2014. 12.5 Lexical Analysis With the token-based data frame, we can perform lexical analysis on the lexical variations on specific social dimensions. 12.5.1 Word Frequency vs. Gender In this section, I would like to demonstrate how to explore the gender differences in language. Let’s assume that we like to know which adjectives are most frequently used by men and women. corp_bnc_adj_gender &lt;- corp_bnc_token_df %&gt;% filter(str_detect(pos, &quot;^(JJ[RT]?$)&quot;)) %&gt;% left_join(bnc_sp_meta, by = c(&quot;who&quot;=&quot;spid&quot;)) %&gt;% mutate(gender = factor(gender, levels=c(&quot;F&quot;,&quot;M&quot;))) %&gt;% filter(!is.na(gender)) corp_bnc_adj_gender %&gt;% head(100) 12.5.2 Frequency and Keyword Analysis After we extract word tokens that are adjectives, we can create a frequency list: freq_adj_by_gender &lt;- corp_bnc_adj_gender %&gt;% count(gender, lemma, sort = T) freq_adj_by_gender %&gt;% group_by(gender) %&gt;% top_n(10, n) %&gt;% ungroup %&gt;% arrange(gender, desc(n)) Female wordcloud require(wordcloud2) freq_adj_by_gender %&gt;% filter(gender==&quot;F&quot;) %&gt;% top_n(100,n) %&gt;% select(lemma, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) Male wordcloud freq_adj_by_gender %&gt;% filter(gender==&quot;M&quot;) %&gt;% top_n(100,n) %&gt;% select(lemma, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) Exercise 12.3 Which adjectives are more often used by male and female speakers? This should be a statistical problem. We can in fact extend our keyword analysis (cf. Chapter 7) to this question. Please use the statistics of keyword analysis to find out the top 20 adjectives that are strongly attracted to female and male speakers according to G2 statistics. Please include in the analysis words whose frequencies &gt;= 20 in the entire corpus. Also, please note the problem of the NaN values out of the log(). 12.6 Constructions Analysis 12.6.1 From Token-based to Turn-based Data Frame We can also conduct analysis of specific constructions. Because constructions often span word boundaries,what we have right now is a token-based data frame of the BNC2014. For construction or multiword-unit analysis, we can convert the token-based DF into a turn-based data frame, but keep necessary token-level annotations relevant to your research project. In this demonstration, I would like to convert the token-based DF into a turn-based DF, and keep the strings of word forms as well as parts-of-speech tags of words for each token. But for non-word tokens, we use the name of the tag, enclosed by &lt; and &gt;, to represent the nature of the extralinguistic annotations in the utteracnes. corp_bnc_token_df &lt;- read_csv(&quot;demo_data/data-corp-token-bnc2014.csv&quot;) head(corp_bnc_token_df) corp_bnc_utterance_df &lt;- corp_bnc_token_df %&gt;% group_by(xml_id, n, who, trans, whoconfidence) %&gt;% nest %&gt;% ungroup extract_wordtag_string &lt;- function(u_df){ utterance_df &lt;- u_df cur_text &lt;-utterance_df$text cur_pos &lt;- utterance_df$pos tag_index &lt;-which(utterance_df$name != &quot;w&quot;) if(length(tag_index)&gt;0){ cur_text[tag_index] &lt;- paste(&quot;&lt;&quot;,utterance_df$name[tag_index],&quot;&gt;&quot;, sep=&quot;&quot;) cur_pos[tag_index] &lt;- paste(&quot;&lt;&quot;,utterance_df$name[tag_index],&quot;&gt;&quot;, sep=&quot;&quot;) } paste(cur_text, cur_pos, sep = &quot;_&quot;, collapse=&quot; &quot;) } corp_bnc_utterance_df %&gt;% mutate(utterance = map_chr(data, extract_wordtag_string)) %&gt;% select(-data) -&gt; corp_bnc_utterance_df corp_bnc_utterance_df %&gt;% head(50) With the above utterance-based DF of the corpus, we can extract constructions or morphosyntactic patterns from the utterance column, utilizing the parts-of-speech tags provided by BNC2014. 12.6.2 Degree ADV + ADJ In this section I would like to show you an example where we can extend our lexical analysis to a particular syntactic pattern. Specifically, I like to look at the adjectives that are emphasized in conversations (e.g., too bad, very good, quite cheap) and examine how these emphatic adjectives may differ in speakers of different genders. Here we define our patterns, utilizing the POS tags and the regular expressions: [^_]+_RG [^_]+_JJ We first extract the target patterns by converting the utterance-based DF into a pattern-based DF. We at the same time link each match with the speaker metadata. corp_bnc_pat_gender &lt;- corp_bnc_utterance_df %&gt;% unnest_tokens(pattern, utterance, token = function(x) str_extract_all(x, &quot;[^_ ]+_RG [^_ ]+_JJ&quot;), to_lower = F) %&gt;% left_join(bnc_sp_meta, by = c(&quot;who&quot;=&quot;spid&quot;)) corp_bnc_pat_gender %&gt;% head(100) Then we can create pattern freqeucies by genders. freq_pat_by_gender &lt;- corp_bnc_pat_gender %&gt;% mutate(pattern = str_replace_all(pattern, &quot;_[^_ ]+&quot;,&quot;&quot;)) %&gt;% # remove pos tags select(gender, pattern) %&gt;% count(gender, pattern, sort=T) # print top 100 freq_pat_by_gender %&gt;% group_by(gender) %&gt;% top_n(10,n) %&gt;% ungroup %&gt;% arrange(gender, desc(n)) We can also create wordclouds for the patterns by gender # wordcloud freq_pat_by_gender %&gt;% filter(gender==&quot;F&quot;) %&gt;% top_n(100, n) %&gt;% select(pattern, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) freq_pat_by_gender %&gt;% filter(gender==&quot;M&quot;) %&gt;% top_n(100, n) %&gt;% select(pattern, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) Exercise 12.4 In the previous task, we have got the frequency list of the patterns (i.e., “Adverb + Adjective”) by gender, i.e., freq_pat_by_gender. Please create a wide version of the frequency list, where each row is a pattern type and the columns include the frequencies of the patterns in male and female speakers, as well as the dispersion of the word in male and female speakers. A sample has been provided below. Dispersion is defined as the number of speakers who use the pattern at least once. Exercise 12.5 So far we have been looking at the constructional schema of ADV + ADJ. Now let’s examine further how adjectives that are emphasized differ among speakers of different genders. That is, do male speakers tend to emphasize adjectives that are different from those that are emphasized by females? Now it should be clear to you that which adjectives are more likely to be emphasized by ADV in male and female utterances should be a statistical question. Please use the statistics G2 from keyword analysis to find out the top 10 Adjectives that are strongly attracted to female and male speakers according to G2 statistics. Please include in the analysis adjectives whose dispersion &gt;= 2 in the respective corpus, i.e., adjectives that have been used by at least TWO different male or female speakers. Also, please note the problem of the NaN values out of the log(). You first need to get the frequency list of the ajectives that occur in this constructional schema, ADV + ADJ: Then you convert the frequency list from a long format into a wide format for keyness computation. With the above distributional information, you can compute the keyness of the adjectives. Exercise 12.6 Please analyze the verbs that co-occur with the first-person pronoun I in BNC2014 in terms of speakers of different genders. Please create a frequency list of the verbs that follow the first person pronoun I in demo_data/corp-bnc-spoken2014-sample. Verbs are defined as any words whose POS tag starts with VV. Also, please create the word clouds of the top 100 verbs for male and female speakers. All verb types on the top 100 lists of male and female speakers: Female Wordcloud Male Wordcloud Exercise 12.7 Please analyze the recurrent trigrams used by male and female speakers by showing the top 20 four-grams used by males and females respectively ranked according to their dispersions. Dispersion of four-grams is defined as the number of texts (i.e., XML files) where the four-gram is observed. "]
]
