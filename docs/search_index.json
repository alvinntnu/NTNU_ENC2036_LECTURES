[["xml.html", "Chapter 11 XML 11.1 BNC Spoken 2014 11.2 Processing one XML file 11.3 Process the Whole Directory of BNC2014 Sample 11.4 Metadata 11.5 BNC2014 for Socio-linguistic Variation 11.6 Lexical Analysis 11.7 Constructions Analysis", " Chapter 11 XML library(tidyverse) library(readtext) library(tidytext) library(quanteda) library(xml2) This chapter shows you how to process the recently released BNC 2014, which is by far the largest representative collection of spoken English collected in UK. For the purpose of our in-class tutorials, I have included a small sample of the BNC2014 in our demo_data. However, the whole dataset is now available via the official website: British National Corpus 2014. Please sign up for the complete access to the corpus if you need this corpus for your own research. 11.1 BNC Spoken 2014 XML (the eXtensible Markup Language) is an effective format for text data storage, where the information of markup and annotation is added to the written texts in a structured way. We can open an XML file with Google Chrome to take a look at its hierarchical structure. Before we process the data, we need to understand the structure of the XML tags in the files. Usually we would start from the documentation of the corpus. Please read The BNC 2014: User Manual amd Reference Guide for more detail. Other than that, the steps are pretty much similar to what we have learned before. In this chapter, we will use xml2 to process XML files. Please see Chapter 3.8.2 Some Notes on Handling XML Data in Gries (2016) for more discussions on XML processing. There are many R libraries supporting XML processing. The library rvest we use in Chapter 3 can also be used to process XML data. In addition to xml2 covered in this chapter, XML is another alternative for XML processing in R. 11.2 Processing one XML file Each BNC XML file is like a tree structure. It starts with text node. Each text consists of utterance nodes u. Each utterance node consists of word nodes w or other para-linguistic feature nodes (e.g., pauses or vocal features). Let’s see how we can process one single XML file from BNC2014 first. The steps include: Parse the XML file using read_xml(); Identity the XML root node using xml_root(); Extract all utterance nodes using xml_find_all(); Extract lexical units (word nodes) from each utterance node as well as their relevant annotations. Output everything as a data frame. First, we read and parse an XML file using read_xml(): ## read one XML corp_bnc&lt;-read_xml(x = &quot;demo_data/corp-bnc-spoken2014-sample/S2A5-tgd.xml&quot;, encoding = &quot;UTF-8&quot;) Second, we identity the XML root using xml_root(): ## Identity the XML root root&lt;- xml_root(corp_bnc) ## Name of xml root xml_name(root) [1] &quot;text&quot; Third, we extract all utterance nodes from the root using xml_find_all(): XPath is a query language that allows us to effectively identify specific elements from HTML/XML documents. We have used this in the task of web crawling in Chapter 3. Please read Chapter 4 XPath in Munzert et al. (2014) very carefully to make sure that you know how to use XPath. ## Extract &lt;u&gt; from XML all_utterances &lt;- xml_find_all(root, xpath = &quot;//u&quot;) ## Check print.AsIs(all_utterances[1]) [[1]] {xml_node} &lt;u n=&quot;1&quot; who=&quot;S0024&quot; trans=&quot;nonoverlap&quot; whoConfidence=&quot;high&quot;&gt; [1] &lt;w pos=&quot;AT1&quot; lemma=&quot;a&quot; class=&quot;ART&quot; usas=&quot;Z5&quot;&gt;an&lt;/w&gt; [2] &lt;w pos=&quot;NNT1&quot; lemma=&quot;hour&quot; class=&quot;SUBST&quot; usas=&quot;T1:3&quot;&gt;hour&lt;/w&gt; [3] &lt;w pos=&quot;RRR&quot; lemma=&quot;later&quot; class=&quot;ADV&quot; usas=&quot;T4&quot;&gt;later&lt;/w&gt; [4] &lt;pause dur=&quot;short&quot;/&gt; [5] &lt;w pos=&quot;VV0&quot; lemma=&quot;hope&quot; class=&quot;VERB&quot; usas=&quot;X2:6&quot;&gt;hope&lt;/w&gt; [6] &lt;w pos=&quot;PPHS1&quot; lemma=&quot;she&quot; class=&quot;PRON&quot; usas=&quot;Z8&quot;&gt;she&lt;/w&gt; [7] &lt;w pos=&quot;VVZ&quot; lemma=&quot;stay&quot; class=&quot;VERB&quot; usas=&quot;M8&quot;&gt;stays&lt;/w&gt; [8] &lt;w pos=&quot;RP&quot; lemma=&quot;down&quot; class=&quot;ADV&quot; usas=&quot;Z5&quot;&gt;down&lt;/w&gt; [9] &lt;pause dur=&quot;short&quot;/&gt; [10] &lt;w pos=&quot;RG&quot; lemma=&quot;rather&quot; class=&quot;ADV&quot; usas=&quot;A13:5&quot;&gt;rather&lt;/w&gt; [11] &lt;w pos=&quot;JJ&quot; lemma=&quot;late&quot; class=&quot;ADJ&quot; usas=&quot;T4&quot;&gt;late&lt;/w&gt; attr(,&quot;class&quot;) [1] &quot;xml_nodeset&quot; print.AsIs(all_utterances[36]) [[1]] {xml_node} &lt;u n=&quot;36&quot; who=&quot;S0144&quot; trans=&quot;nonoverlap&quot; whoConfidence=&quot;high&quot;&gt; [1] &lt;vocal desc=&quot;laugh&quot;/&gt; [2] &lt;pause dur=&quot;short&quot;/&gt; [3] &lt;w pos=&quot;DD1&quot; lemma=&quot;that&quot; class=&quot;ADJ&quot; usas=&quot;Z8&quot;&gt;that&lt;/w&gt; [4] &lt;w pos=&quot;VBDZ&quot; lemma=&quot;be&quot; class=&quot;VERB&quot; usas=&quot;A3&quot;&gt;was&lt;/w&gt; [5] &lt;w pos=&quot;AT1&quot; lemma=&quot;a&quot; class=&quot;ART&quot; usas=&quot;Z5&quot;&gt;a&lt;/w&gt; [6] &lt;w pos=&quot;JJ&quot; lemma=&quot;funny&quot; class=&quot;ADJ&quot; usas=&quot;E4:1&quot;&gt;funny&lt;/w&gt; [7] &lt;w pos=&quot;NN1&quot; lemma=&quot;noise&quot; class=&quot;SUBST&quot; usas=&quot;X3:2&quot;&gt;noise&lt;/w&gt; attr(,&quot;class&quot;) [1] &quot;xml_nodeset&quot; From the above output, we can see that under the &lt;u&gt; node, we may expect not only word nodes &lt;w&gt; but also non-word tokens, such as &lt;pause .../&gt;, &lt;desc .../&gt;. Fourth, we need to extract all the children nodes (i.e., word and non-word nodes) from each utterance. This can be more complicated because each word node has a lot of annotations as attribute-value pairs in the start tag &lt;w ...&gt;. Here let’s use the first utterance as an example. We can do the following: Extract all children nodes of the current utterance using xml_children(); Extract the corpus texts of each children node using xml_text(); Extract annotations from each children node using xml_attr(); ## Example print.AsIs(all_utterances[1]) [[1]] {xml_node} &lt;u n=&quot;1&quot; who=&quot;S0024&quot; trans=&quot;nonoverlap&quot; whoConfidence=&quot;high&quot;&gt; [1] &lt;w pos=&quot;AT1&quot; lemma=&quot;a&quot; class=&quot;ART&quot; usas=&quot;Z5&quot;&gt;an&lt;/w&gt; [2] &lt;w pos=&quot;NNT1&quot; lemma=&quot;hour&quot; class=&quot;SUBST&quot; usas=&quot;T1:3&quot;&gt;hour&lt;/w&gt; [3] &lt;w pos=&quot;RRR&quot; lemma=&quot;later&quot; class=&quot;ADV&quot; usas=&quot;T4&quot;&gt;later&lt;/w&gt; [4] &lt;pause dur=&quot;short&quot;/&gt; [5] &lt;w pos=&quot;VV0&quot; lemma=&quot;hope&quot; class=&quot;VERB&quot; usas=&quot;X2:6&quot;&gt;hope&lt;/w&gt; [6] &lt;w pos=&quot;PPHS1&quot; lemma=&quot;she&quot; class=&quot;PRON&quot; usas=&quot;Z8&quot;&gt;she&lt;/w&gt; [7] &lt;w pos=&quot;VVZ&quot; lemma=&quot;stay&quot; class=&quot;VERB&quot; usas=&quot;M8&quot;&gt;stays&lt;/w&gt; [8] &lt;w pos=&quot;RP&quot; lemma=&quot;down&quot; class=&quot;ADV&quot; usas=&quot;Z5&quot;&gt;down&lt;/w&gt; [9] &lt;pause dur=&quot;short&quot;/&gt; [10] &lt;w pos=&quot;RG&quot; lemma=&quot;rather&quot; class=&quot;ADV&quot; usas=&quot;A13:5&quot;&gt;rather&lt;/w&gt; [11] &lt;w pos=&quot;JJ&quot; lemma=&quot;late&quot; class=&quot;ADJ&quot; usas=&quot;T4&quot;&gt;late&lt;/w&gt; attr(,&quot;class&quot;) [1] &quot;xml_nodeset&quot; ## Extract all children nodes (all_children &lt;- xml_children(all_utterances[1])) {xml_nodeset (11)} [1] &lt;w pos=&quot;AT1&quot; lemma=&quot;a&quot; class=&quot;ART&quot; usas=&quot;Z5&quot;&gt;an&lt;/w&gt; [2] &lt;w pos=&quot;NNT1&quot; lemma=&quot;hour&quot; class=&quot;SUBST&quot; usas=&quot;T1:3&quot;&gt;hour&lt;/w&gt; [3] &lt;w pos=&quot;RRR&quot; lemma=&quot;later&quot; class=&quot;ADV&quot; usas=&quot;T4&quot;&gt;later&lt;/w&gt; [4] &lt;pause dur=&quot;short&quot;/&gt; [5] &lt;w pos=&quot;VV0&quot; lemma=&quot;hope&quot; class=&quot;VERB&quot; usas=&quot;X2:6&quot;&gt;hope&lt;/w&gt; [6] &lt;w pos=&quot;PPHS1&quot; lemma=&quot;she&quot; class=&quot;PRON&quot; usas=&quot;Z8&quot;&gt;she&lt;/w&gt; [7] &lt;w pos=&quot;VVZ&quot; lemma=&quot;stay&quot; class=&quot;VERB&quot; usas=&quot;M8&quot;&gt;stays&lt;/w&gt; [8] &lt;w pos=&quot;RP&quot; lemma=&quot;down&quot; class=&quot;ADV&quot; usas=&quot;Z5&quot;&gt;down&lt;/w&gt; [9] &lt;pause dur=&quot;short&quot;/&gt; [10] &lt;w pos=&quot;RG&quot; lemma=&quot;rather&quot; class=&quot;ADV&quot; usas=&quot;A13:5&quot;&gt;rather&lt;/w&gt; [11] &lt;w pos=&quot;JJ&quot; lemma=&quot;late&quot; class=&quot;ADJ&quot; usas=&quot;T4&quot;&gt;late&lt;/w&gt; ## Extract tag names of all children nodes (token_names &lt;- xml_name(all_children)) [1] &quot;w&quot; &quot;w&quot; &quot;w&quot; &quot;pause&quot; &quot;w&quot; &quot;w&quot; &quot;w&quot; &quot;w&quot; &quot;pause&quot; [10] &quot;w&quot; &quot;w&quot; ## Extract texts of all children nodes (token_texts &lt;- xml_text(all_children)) [1] &quot;an&quot; &quot;hour&quot; &quot;later&quot; &quot;&quot; &quot;hope&quot; &quot;she&quot; &quot;stays&quot; &quot;down&quot; [9] &quot;&quot; &quot;rather&quot; &quot;late&quot; ## Extract annotations of all children nodes (token_pos &lt;- xml_attr(all_children, attr=&quot;pos&quot;)) ## POS [1] &quot;AT1&quot; &quot;NNT1&quot; &quot;RRR&quot; NA &quot;VV0&quot; &quot;PPHS1&quot; &quot;VVZ&quot; &quot;RP&quot; NA [10] &quot;RG&quot; &quot;JJ&quot; (token_lemma &lt;- xml_attr(all_children, attr=&quot;lemma&quot;)) ## lemma [1] &quot;a&quot; &quot;hour&quot; &quot;later&quot; NA &quot;hope&quot; &quot;she&quot; &quot;stay&quot; &quot;down&quot; [9] NA &quot;rather&quot; &quot;late&quot; (token_class &lt;- xml_attr(all_children, attr=&quot;class&quot;)) ## POS [1] &quot;ART&quot; &quot;SUBST&quot; &quot;ADV&quot; NA &quot;VERB&quot; &quot;PRON&quot; &quot;VERB&quot; &quot;ADV&quot; NA [10] &quot;ADV&quot; &quot;ADJ&quot; (token_usas &lt;- xml_attr(all_children, attr=&quot;usas&quot;)) ## semantic tag [1] &quot;Z5&quot; &quot;T1:3&quot; &quot;T4&quot; NA &quot;X2:6&quot; &quot;Z8&quot; &quot;M8&quot; &quot;Z5&quot; NA [10] &quot;A13:5&quot; &quot;T4&quot; ## Create DF cur_utterance_df &lt;- data.frame( names = token_names, texts = token_texts, pos = token_pos, lemma = token_lemma, class = token_class, usas = token_usas ) cur_utterance_df In the result data frame above, we can see that there are quite a few rows which have NA values across all columns. Do you know why? Take the first utterance node of the XML document for example. Each utterance node includes words as well as non-word tokens (i.e., para-linguistic annotations &lt;pause .../&gt;). We can retrieve: Strings of words in an utterance Lemma forms of all words in the utterance POS tags of all words in the utterance (BNC2014 uses UCREL CLAWS6 Tagset) Paralinguistic tags in the utterance With the above example, it seems that we have completed the processing of the first utterance node and extracted most information we need from the first utterance. But there are still more we can extract from the utterance node: We can extract more information about the paralinguistic tags (e.g., &lt;pause .../&gt;, &lt;vocal .../&gt;) ## Check again the paralinguistic tags print.AsIs(all_utterances[1]) [[1]] {xml_node} &lt;u n=&quot;1&quot; who=&quot;S0024&quot; trans=&quot;nonoverlap&quot; whoConfidence=&quot;high&quot;&gt; [1] &lt;w pos=&quot;AT1&quot; lemma=&quot;a&quot; class=&quot;ART&quot; usas=&quot;Z5&quot;&gt;an&lt;/w&gt; [2] &lt;w pos=&quot;NNT1&quot; lemma=&quot;hour&quot; class=&quot;SUBST&quot; usas=&quot;T1:3&quot;&gt;hour&lt;/w&gt; [3] &lt;w pos=&quot;RRR&quot; lemma=&quot;later&quot; class=&quot;ADV&quot; usas=&quot;T4&quot;&gt;later&lt;/w&gt; [4] &lt;pause dur=&quot;short&quot;/&gt; [5] &lt;w pos=&quot;VV0&quot; lemma=&quot;hope&quot; class=&quot;VERB&quot; usas=&quot;X2:6&quot;&gt;hope&lt;/w&gt; [6] &lt;w pos=&quot;PPHS1&quot; lemma=&quot;she&quot; class=&quot;PRON&quot; usas=&quot;Z8&quot;&gt;she&lt;/w&gt; [7] &lt;w pos=&quot;VVZ&quot; lemma=&quot;stay&quot; class=&quot;VERB&quot; usas=&quot;M8&quot;&gt;stays&lt;/w&gt; [8] &lt;w pos=&quot;RP&quot; lemma=&quot;down&quot; class=&quot;ADV&quot; usas=&quot;Z5&quot;&gt;down&lt;/w&gt; [9] &lt;pause dur=&quot;short&quot;/&gt; [10] &lt;w pos=&quot;RG&quot; lemma=&quot;rather&quot; class=&quot;ADV&quot; usas=&quot;A13:5&quot;&gt;rather&lt;/w&gt; [11] &lt;w pos=&quot;JJ&quot; lemma=&quot;late&quot; class=&quot;ADJ&quot; usas=&quot;T4&quot;&gt;late&lt;/w&gt; attr(,&quot;class&quot;) [1] &quot;xml_nodeset&quot; print.AsIs(all_utterances[36]) [[1]] {xml_node} &lt;u n=&quot;36&quot; who=&quot;S0144&quot; trans=&quot;nonoverlap&quot; whoConfidence=&quot;high&quot;&gt; [1] &lt;vocal desc=&quot;laugh&quot;/&gt; [2] &lt;pause dur=&quot;short&quot;/&gt; [3] &lt;w pos=&quot;DD1&quot; lemma=&quot;that&quot; class=&quot;ADJ&quot; usas=&quot;Z8&quot;&gt;that&lt;/w&gt; [4] &lt;w pos=&quot;VBDZ&quot; lemma=&quot;be&quot; class=&quot;VERB&quot; usas=&quot;A3&quot;&gt;was&lt;/w&gt; [5] &lt;w pos=&quot;AT1&quot; lemma=&quot;a&quot; class=&quot;ART&quot; usas=&quot;Z5&quot;&gt;a&lt;/w&gt; [6] &lt;w pos=&quot;JJ&quot; lemma=&quot;funny&quot; class=&quot;ADJ&quot; usas=&quot;E4:1&quot;&gt;funny&lt;/w&gt; [7] &lt;w pos=&quot;NN1&quot; lemma=&quot;noise&quot; class=&quot;SUBST&quot; usas=&quot;X3:2&quot;&gt;noise&lt;/w&gt; attr(,&quot;class&quot;) [1] &quot;xml_nodeset&quot; We can extract utterance-level metadata as well (i.e., the attributes of the &lt;u&gt; node). its unique index (n) speaker id (who) transition type (trans, i.e., whether or not the transition between turns was overlapping) attribution confidence (whoconfidence, whether or not the transcriber was confident that they had correctly identified the speaker of the turn) ## node-level attributes xml_attrs(all_utterances[1]) [[1]] n who trans whoConfidence &quot;1&quot; &quot;S0024&quot; &quot;nonoverlap&quot; &quot;high&quot; Exercise 11.1 Now we know how to extract token-level information and utterance-level annotation from each utterance. Please come up with a way to extract all relevant linguistic data from all utterances in the file demo_data/corp-bnc-spoken2014-sample/S2A5-tgd.xml, including their word and non-word tokens as well as their annotations and utterance-level metadata. Ideally, the resulting data frame should consist of rows being the tokens of the utterances, and columns including the attributes and metadata of each token. Specifically, for the word tokens, the data frame should include not only the word strings, but also the word-level annotations of part-of-speech tags, lemmas, and semantic tags (i.e., usas). For non-word tokens (paralinguistic tags), the data frame should also include their information of attributes in a column, called notes. Also, each token is connected to the utterance-level metadata, such as the utterance ID, speaker ID etc. A sample data frame of the XML file is provided below (Only No 1 and 36 utterance nodes are included in the data frame for your reference). 11.3 Process the Whole Directory of BNC2014 Sample 11.3.1 Define Function In Section 11.1, if you have figured out how to extract the token-based data frame from all utterances in an XML file, you can easily wrap the whole procedure as one function. With this function, we can perform the same procedure to all the xml files of the BNC2014. For example, let’s assume that we have defined a function: read_xml_bnc2014 &lt;- function(xml){ ... ... ... } # endfunc This function takes one xml file as an argument and returns a token-based data frame, consisting of token strings and other relevant utterance-level and token-level information from the xml. word_df &lt;- read_xml_bnc2014( xmlfile = &quot;demo_data/corp-bnc-spoken2014-sample/S2A5-tgd.xml&quot;) word_df %&gt;% filter(n %in% c(&quot;1&quot;,&quot;36&quot;)) Exercise 11.2 Now your job is to create this function, read_xml_bnc2014(xmlfile = \"\"). The function should take the path to one XML file as the input and return a token-based data frame of the XML file as shown above. 11.3.2 Apply Function Now we can utilize the self-defined function, read_xml_bnc2014(), and process all XML files in the demo_data/corp-bnc-spoken2014-sample/. Then we combine the individual data.frame returned from each XML into a bigger one, i.e., corp_bnc_token_df: ## Get all XML filenames bnc_flist &lt;- dir(&quot;demo_data/corp-bnc-spoken2014-sample/&quot;,full.names = T) ## Extract token-based df from each XML system.time(corp_bnc_list &lt;- map(bnc_flist, read_xml_bnc2014)) ## Combine all df&#39;s corp_bnc_token_df &lt;- bind_rows(corp_bnc_list) ## save file write_csv(corp_bnc_token_df, file= &quot;demo_data/data-corp-token-bnc2014.csv&quot;) It takes a while to process/parse all the files included in the sample directory because we parse the entire XML file and extract almost everything (annotations + metadata) from the file. You may store this corp_bnc_token_df data frame output for later use so that you don’t have to process the XML files every time you work with BNC2014. The parsed token-based data frame of the BNC2014 is available in our demo_data/data-corp-token-bnc2014.csv. You can check if your output is the same as the CSV in the demo_data. ## Loading corp_bnc_token_df &lt;- read_csv(file = &quot;demo_data/data-corp-token-bnc2014.csv&quot;, locale = locale(encoding = &quot;UTF-8&quot;)) ## Checking corp_bnc_token_df %&gt;% filter(xml_id == &quot;S2A5-tgd.xml&quot; &amp; n %in% c(&quot;1&quot;,&quot;36&quot;)) Also, in addition to &lt;pause&gt; and &lt;vocal&gt;, there are many other non-word tokens under the utterance nodes: corp_bnc_token_df %&gt;% count(name, sort = TRUE) You may check the BNC2014 documentation for more detail about the meanings of these XML tags. 11.4 Metadata The best thing about BNC2014 is its rich demographic information relating to the settings and speakers of the conversations collected. The whole corpus comes with two metadata sets: bnc2014spoken-textdata.tsv: metadata for each text transcript bnc2014spoken-speakerdata.tsv: metadata for each speaker ID These two metadata sets allow us to get more information about each transcript as well as the speakers within those transcripts. 11.4.1 Text Metadata There are two files that are relevant to the text metadata: bnc2014spoken-textdata.tsv: This file includes the header/metadata information of each text file metadata-fields-text.txt: This file includes the column names/meanings of the previous text metadata tsv, i.e., bnc2014spoken-textdata.tsv. ## text metadata bnc_text_meta &lt;- read_tsv( file = &quot;demo_data/corp-bnc-spoken2014-metadata/bnc2014spoken-textdata.tsv&quot;, col_names = FALSE, locale = locale(encoding = &quot;UTF-8&quot;) ) bnc_text_meta ## columns about text metadata bnc_text_meta_names &lt;- read_tsv( file = &quot;demo_data/corp-bnc-spoken2014-metadata/metadata-fields-text.txt&quot;, skip = 2, col_names = F, locale = locale(encoding = &quot;UTF-8&quot;) ) bnc_text_meta_names ## Rename the columns of text metadata names(bnc_text_meta) &lt;- c(&quot;textid&quot;, bnc_text_meta_names$X2) bnc_text_meta 11.4.2 Speaker Metadata There are two files that are relevant to the speaker metadata: bnc2014spoken-speakerdata.tsv: This file includes the demographic information of each speaker metadata-fields-speaker.txt: This file includes the column names/meanings of the previous speaker metadata tsv, i.e., bnc2014spoken-speakerdata.tsv. bnc_sp_meta &lt;- read_tsv(&quot;demo_data/corp-bnc-spoken2014-metadata/bnc2014spoken-speakerdata.tsv&quot;, col_names = F) bnc_sp_meta bnc_sp_meta_names &lt;- read_tsv(&quot;demo_data/corp-bnc-spoken2014-metadata/metadata-fields-speaker.txt&quot;, skip = 3, col_names = F) bnc_sp_meta_names names(bnc_sp_meta) &lt;- c(&quot;spid&quot;, bnc_sp_meta_names$X2) bnc_sp_meta 11.5 BNC2014 for Socio-linguistic Variation Now with both the text-level and speaker-level metadata, bnc_text_meta and bnc_sp_meta, we can easily connect the utterances to speaker and text profiles using their unique ID’s. BNC2014 was born for the study of socio-linguistic variation. Here I would like to show you some naive examples, but you should get the ideas and the potentials of BNC2014. 11.6 Lexical Analysis With the token-based data frame, we can perform lexical analysis on the lexical variations on specific social dimensions. 11.6.1 Word Frequency vs. Gender In this section, I would like to demonstrate how to explore the gender differences in language. Let’s assume that we like to know which adjectives are most frequently used by men and women. corp_bnc_adj_gender &lt;- corp_bnc_token_df %&gt;% filter(str_detect(pos, &quot;^(JJ[RT]?$)&quot;)) %&gt;% left_join(bnc_sp_meta, by = c(&quot;who&quot;=&quot;spid&quot;)) %&gt;% mutate(gender = factor(gender, levels=c(&quot;F&quot;,&quot;M&quot;))) %&gt;% filter(!is.na(gender)) corp_bnc_adj_gender %&gt;% head(100) 11.6.2 Frequency and Keyword Analysis After we extract word tokens that are adjectives, we can create a frequency list: freq_adj_by_gender &lt;- corp_bnc_adj_gender %&gt;% count(gender, lemma, sort = T) freq_adj_by_gender %&gt;% group_by(gender) %&gt;% top_n(10, n) %&gt;% ungroup %&gt;% arrange(gender, desc(n)) Female wordcloud require(wordcloud2) freq_adj_by_gender %&gt;% filter(gender==&quot;F&quot;) %&gt;% top_n(100,n) %&gt;% select(lemma, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) Male wordcloud freq_adj_by_gender %&gt;% filter(gender==&quot;M&quot;) %&gt;% top_n(100,n) %&gt;% select(lemma, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) Exercise 11.3 Which adjectives are more often used by male and female speakers? This should be a statistical problem. We can in fact extend our keyword analysis (cf. Chapter 6) to this question. Please use the statistics of keyword analysis to find out the top 20 adjectives that are strongly attracted to female and male speakers according to G2 statistics. Please include in the analysis words whose frequencies &gt;= 20 in the entire corpus. Also, please note the problem of the NaN values out of the log(). 11.7 Constructions Analysis 11.7.1 From Token-based to Turn-based Data Frame We can also conduct analysis of specific constructions. Because constructions often span word boundaries, what we have right now is a token-based data frame of the BNC2014. For construction or multiword-unit analysis, we can convert the token-based DF into a turn-based DF, but keep necessary token-level annotations relevant to your research project. In this demonstration, I would like to convert the token-based DF into a turn-based DF, and keep the strings of word forms as well as parts-of-speech tags of words for each token. But for non-word tokens, we use the name of the tag, enclosed by &lt; and &gt;, to represent the nature of the extralinguistic annotations in the utterances. corp_bnc_token_df &lt;- read_csv(&quot;demo_data/data-corp-token-bnc2014.csv&quot;, locale = locale(encoding = &quot;UTF-8&quot;)) head(corp_bnc_token_df) corp_bnc_utterance_df &lt;- corp_bnc_token_df %&gt;% group_by(xml_id, n, who, trans, whoconfidence) %&gt;% nest %&gt;% ungroup extract_wordtag_string &lt;- function(u_df){ utterance_df &lt;- u_df cur_text &lt;-utterance_df$text cur_pos &lt;- utterance_df$pos tag_index &lt;-which(is.na(cur_text)) if(length(tag_index)&gt;0){ cur_text[tag_index] &lt;- paste0(&quot;&lt;&quot;,utterance_df$name[tag_index],&quot;&gt;&quot;, sep =&quot;&quot;) cur_pos[tag_index] &lt;- paste0(&quot;&lt;&quot;,utterance_df$name[tag_index],&quot;&gt;&quot;, sep =&quot;&quot;) } paste(cur_text, cur_pos, sep = &quot;_&quot;, collapse=&quot; &quot;) } corp_bnc_utterance_df %&gt;% mutate(utterance = map_chr(data, extract_wordtag_string)) %&gt;% select(-data) -&gt; corp_bnc_utterance_df corp_bnc_utterance_df %&gt;% head(50) With the above utterance-based DF of the corpus, we can extract constructions or morphosyntactic patterns from the utterance column, utilizing the parts-of-speech tags provided by BNC2014. 11.7.2 Degree ADV + ADJ In this section I would like to show you an example where we can extend our lexical analysis to a particular syntactic pattern. Specifically, I like to look at the adjectives that are emphasized in conversations (e.g., too bad, very good, quite cheap) and examine how these emphatic adjectives may differ in speakers of different genders. Here we define our patterns, utilizing the POS tags and the regular expressions: [^_]+_RG [^_]+_JJ We first extract the target patterns by converting the utterance-based DF into a pattern-based DF. We at the same time link each match with the speaker metadata. corp_bnc_pat_gender &lt;- corp_bnc_utterance_df %&gt;% unnest_tokens(pattern, utterance, token = function(x) str_extract_all(x, &quot;[^_ ]+_RG [^_ ]+_JJ&quot;), to_lower = F) %&gt;% left_join(bnc_sp_meta, by = c(&quot;who&quot;=&quot;spid&quot;)) corp_bnc_pat_gender %&gt;% head(100) Then we can create pattern freqeucies by genders. freq_pat_by_gender &lt;- corp_bnc_pat_gender %&gt;% mutate(pattern = str_replace_all(pattern, &quot;_[^_ ]+&quot;,&quot;&quot;)) %&gt;% # remove pos tags select(gender, pattern) %&gt;% count(gender, pattern, sort=T) # print top 100 freq_pat_by_gender %&gt;% group_by(gender) %&gt;% top_n(10,n) %&gt;% ungroup %&gt;% arrange(gender, desc(n)) We can also create wordclouds for the patterns by gender # wordcloud freq_pat_by_gender %&gt;% filter(gender==&quot;F&quot;) %&gt;% top_n(100, n) %&gt;% select(pattern, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) freq_pat_by_gender %&gt;% filter(gender==&quot;M&quot;) %&gt;% top_n(100, n) %&gt;% select(pattern, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) Exercise 11.4 In the previous task, we have got the frequency list of the patterns (i.e., “Adverb + Adjective”) by gender, i.e., freq_pat_by_gender. Please create a wide version of the frequency list, where each row is a pattern type and the columns include the frequencies of the patterns in male and female speakers, as well as the dispersion of the pattern in male and female speakers. A sample has been provided below. Dispersion is defined as the number of speakers who use the pattern at least once. Exercise 11.5 So far we have been looking at the constructional schema of ADV + ADJ. Now let’s examine further how adjectives that are emphasized differ among speakers of different genders. That is, do male speakers tend to emphasize adjectives that are different from those that are emphasized by females? Now it should be clear to you that which adjectives are more likely to be emphasized by ADV in male and female utterances should be a statistical question. Please use the statistics G2 from keyword analysis to find out the top 10 Adjectives that are strongly attracted to female and male speakers according to G2 statistics. Please include in the analysis adjectives whose dispersion &gt;= 2 in the respective corpus, i.e., adjectives that have been used by at least TWO different male or female speakers. Also, please note the problem of the NaN values out of the log(). You first need to get the frequency list of the ajectives that occur in this constructional schema, ADV + ADJ: Then you convert the frequency list from a long format into a wide format for keyness computation. With the above distributional information, you can compute the keyness of the adjectives. Exercise 11.6 Please analyze the verbs that co-occur with the first-person pronoun I in BNC2014 in terms of speakers of different genders. Please create a frequency list of the verbs that follow the first person pronoun I in demo_data/corp-bnc-spoken2014-sample. Verbs are defined as any words whose POS tag starts with VV. Also, please create the word clouds of the top 100 verbs for male and female speakers. All verb types on the top 100 lists of male and female speakers: Female Wordcloud Male Wordcloud Exercise 11.7 Please analyze the recurrent four-grams used by male and female speakers by showing the top 20 four-grams used by males and females respectively ranked according to their dispersions. Dispersion of four-grams is defined as the number of texts (i.e., XML files) where the four-gram is observed. References Gries, S. T. (2016). Quantitative corpus linguistics with R: A practical introduction (2nd ed.). Routledge. Munzert, S., Rubba, C., Meißner, P., &amp; Nyhuis, D. (2014). Automated data collection with R: A practical guide to web scraping and text mining. John Wiley &amp; Sons. "]]
