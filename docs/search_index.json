[
["ckiptagger.html", "Chapter 10 CKIP Tagger 10.1 Installation 10.2 Download the Model Files 10.3 R-Python Communication 10.4 Word Segmentation in R 10.5 R Environment Setting 10.6 Creating Conda Environment for ckiptagger 10.7 Initialization 10.8 Segmenting Texts 10.9 Define Own Dictionary 10.10 Beyond Word Boundaries 10.11 Tidy Up the Results", " Chapter 10 CKIP Tagger library(tidyverse) library(reticulate) The current state-of-art Chinese segmenter for Taiwan Mandarin available is probably the CKIP tagger, created by the Chinese Knowledge and Information Processing (CKIP) group at the Academia Sinica. The ckiptagger is released as a python module. In this chpater, I will demonstrate how to use the module for Chinese word segmentation but in an R environment, i.e., how to integrate Python modules in R coherently to perform complex tasks. 10.1 Installation Because ckiptagger is built in python, we need to have python installed in our working environment. Please install the following applications on your own before you start: Anaconda + Python 3.6+ ckiptagger module in Python (Please install the module using the Anaconda Navigator or pip install in the terminal) (Please consult the github of the ckiptagger for more details on installation.) For some reasons, the module ckiptagger may not be found in the base channel. In Anaconda Navigator, if you cannot find this module, please add specifically the following channel to the environment so that your Anaconda can find ckiptagger module: https://conda.anaconda.org/roccqqck 10.2 Download the Model Files All NLP applications have their models behind their fancy performances. To use the tagger provided in ckiptagger, we need to download their pre-trained model files. Please go to the github of CKIP tagger to download the model files, which is provided as a zipped file. (The file is very big. It takes a while.) After you download the zipped file, unzip it under your working directory to the data/ directory. 10.3 R-Python Communication In order to call Python functions in R/Rstudio, we need to install an R library in your R. The R-Python communication is made possible through the R library reticulate. Please make sure that you have this library installed in your R. install.packages(&quot;reticulate&quot;) 10.4 Word Segmentation in R Before we proceed, please check if you have everything ready (The following includes the versions of the modules used for this session): Anaconda + Python 3.6+ (Python 3.6.10) Python modules: ckiptagger (ckiptagger 0.1.1 + tensorflow 1.13.1) R library: reticulate(reticulate 1.15) CKIP model files under your working directory ./data If yes, then we are ready to go. 10.5 R Environment Setting We first load the library reticulate and specify in R which Python we will be using in the current R(It is highly likely that there is more than one Python version installed in your system). Please change the path_to_python to your own path, which includes the Anaconda Python you just installed. library(reticulate) 10.6 Creating Conda Environment for ckiptagger I would suggest to install all necessary Python modules in a conda environment and use it in R. In the following demonstration, I assume that you have created a conda environment ckiptagger, where all the necessary modules (i.e., ckiptagger, tensorflow) have been pip-installed. # isntsall in terminal source activate CONDA_ENVIRONMENT_NAME pip install -U ckiptagger conda deactivate 10.7 Initialization There are three important steps in initialization before you can perform word segmentation in R: Activate a specific conda environment in R Import the ckiptagger module in R Initialize the tagger models # Activate a specific conda env in R use_condaenv(&quot;spacy_condaenv&quot;) ## Import ckiptagger module ckip &lt;- reticulate::import(module = &quot;ckiptagger&quot;) ## Intialize models ws &lt;- ckip$WS(&quot;./data&quot;) 10.8 Segmenting Texts The initialized word segmenter object, ws(), can tokenize any input character vectors into a list of word vectors of the same size. ## Raw text corpus texts &lt;- c(&quot;傅達仁今將執行安樂死，卻突然爆出自己20年前遭緯來體育台封殺，他不懂自己哪裡得罪到電視台。&quot;, &quot;美國參議院針對今天總統布什所提名的勞工部長趙小蘭展開認可聽證會，預料她將會很順利通過參議院支持，成為該國有史以來第一位的華裔女性內閣成員。&quot;, &quot;土地公有政策?？還是土地婆有政策。.&quot;, &quot;… 你確定嗎… 不要再騙了……他來亂的啦&quot;, &quot;最多容納59,000個人,或5.9萬人,再多就不行了.這是環評的結論.&quot;, &quot;科長說:1,坪數對人數為1:3。2,可以再增加。&quot;) words &lt;- ws(texts) words ## [[1]] ## [1] &quot;傅達仁&quot; &quot;今&quot; &quot;將&quot; &quot;執行&quot; &quot;安樂死&quot; &quot;，&quot; &quot;卻&quot; &quot;突然&quot; ## [9] &quot;爆出&quot; &quot;自己&quot; &quot;20&quot; &quot;年&quot; &quot;前&quot; &quot;遭&quot; &quot;緯來&quot; &quot;體育台&quot; ## [17] &quot;封殺&quot; &quot;，&quot; &quot;他&quot; &quot;不&quot; &quot;懂&quot; &quot;自己&quot; &quot;哪裡&quot; &quot;得罪到&quot; ## [25] &quot;電視台&quot; &quot;。&quot; ## ## [[2]] ## [1] &quot;美國&quot; &quot;參議院&quot; &quot;針對&quot; &quot;今天&quot; &quot;總統&quot; &quot;布什&quot; ## [7] &quot;所&quot; &quot;提名&quot; &quot;的&quot; &quot;勞工部長&quot; &quot;趙小蘭&quot; &quot;展開&quot; ## [13] &quot;認可&quot; &quot;聽證會&quot; &quot;，&quot; &quot;預料&quot; &quot;她&quot; &quot;將&quot; ## [19] &quot;會&quot; &quot;很&quot; &quot;順利&quot; &quot;通過&quot; &quot;參議院&quot; &quot;支持&quot; ## [25] &quot;，&quot; &quot;成為&quot; &quot;該&quot; &quot;國&quot; &quot;有史以來&quot; &quot;第一&quot; ## [31] &quot;位&quot; &quot;的&quot; &quot;華裔&quot; &quot;女性&quot; &quot;內閣&quot; &quot;成員&quot; ## [37] &quot;。&quot; ## ## [[3]] ## [1] &quot;土地公&quot; &quot;有&quot; &quot;政策&quot; &quot;?&quot; &quot;？&quot; &quot;還是&quot; &quot;土地&quot; &quot;婆&quot; ## [9] &quot;有&quot; &quot;政策&quot; &quot;。&quot; &quot;.&quot; ## ## [[4]] ## [1] &quot;…&quot; &quot; &quot; &quot;你&quot; &quot;確定&quot; &quot;嗎&quot; &quot;…&quot; &quot; &quot; &quot;不要&quot; &quot;再&quot; &quot;騙&quot; ## [11] &quot;了&quot; &quot;…&quot; &quot;…&quot; &quot;他&quot; &quot;來&quot; &quot;亂&quot; &quot;的&quot; &quot;啦&quot; ## ## [[5]] ## [1] &quot;最多&quot; &quot;容納&quot; &quot;59,000&quot; &quot;個&quot; &quot;人&quot; &quot;,&quot; &quot;或&quot; &quot;5.9萬&quot; ## [9] &quot;人&quot; &quot;,&quot; &quot;再&quot; &quot;多&quot; &quot;就&quot; &quot;不行&quot; &quot;了&quot; &quot;.&quot; ## [17] &quot;這&quot; &quot;是&quot; &quot;環評&quot; &quot;的&quot; &quot;結論&quot; &quot;.&quot; ## ## [[6]] ## [1] &quot;科長&quot; &quot;說&quot; &quot;:1,&quot; &quot;坪數&quot; &quot;對&quot; &quot;人數&quot; &quot;為&quot; &quot;1:3&quot; &quot;。&quot; &quot;2&quot; ## [11] &quot;,&quot; &quot;可以&quot; &quot;再&quot; &quot;增加&quot; &quot;。&quot; The word segmenter ws() returns a list object, each element of which is a word-based vector of the original sentence. 10.9 Define Own Dictionary The performance of Chinese word segmenter depends highly on the dictionary. Texts in different disciplines may have very domain-specific vocabulary. To prioritize a set of words in a dictionary, we can further ensure the accuracy of the word segmentation. To create a dictionary for ckiptagger, we need a named list, i.e., to create a list with element names = “the new words” and element values = “the weights”. Then we use the python function ckip$construct_dictionary() to create the dictionary Python object, which is the input argument for word segmenter ws(..., recommend_dictionary = ...). # Define new words in own dictionary new_words &lt;- c(&quot;土地公有&quot;, &quot;土地公&quot;, &quot;土地婆&quot;, &quot;來亂的&quot;, &quot;啦&quot;, &quot;緯來體育台&quot;) # Transform the `vector` into `list` for Python new_words_py &lt;- c(2, 1, 1, 1, 1, 1) %&gt;% as.list # cf. `list(rep, 1 , length(new_words))` names(new_words_py) &lt;- new_words # To create a dictionary for `construct_dictionary()` # We need a list, with names as the words and list elements as the weights in the dictionary # Create Python `dictionary` object, required by `ckiptagger.wc()` dictionary&lt;-ckip$construct_dictionary(new_words_py) # Segment texts using dictionary words_1 &lt;- ws(texts, recommend_dictionary = dictionary) words_1 ## [[1]] ## [1] &quot;傅達仁&quot; &quot;今&quot; &quot;將&quot; &quot;執行&quot; &quot;安樂死&quot; ## [6] &quot;，&quot; &quot;卻&quot; &quot;突然&quot; &quot;爆出&quot; &quot;自己&quot; ## [11] &quot;20&quot; &quot;年&quot; &quot;前&quot; &quot;遭&quot; &quot;緯來體育台&quot; ## [16] &quot;封殺&quot; &quot;，&quot; &quot;他&quot; &quot;不&quot; &quot;懂&quot; ## [21] &quot;自己&quot; &quot;哪裡&quot; &quot;得罪到&quot; &quot;電視台&quot; &quot;。&quot; ## ## [[2]] ## [1] &quot;美國&quot; &quot;參議院&quot; &quot;針對&quot; &quot;今天&quot; &quot;總統&quot; &quot;布什&quot; ## [7] &quot;所&quot; &quot;提名&quot; &quot;的&quot; &quot;勞工部長&quot; &quot;趙小蘭&quot; &quot;展開&quot; ## [13] &quot;認可&quot; &quot;聽證會&quot; &quot;，&quot; &quot;預料&quot; &quot;她&quot; &quot;將&quot; ## [19] &quot;會&quot; &quot;很&quot; &quot;順利&quot; &quot;通過&quot; &quot;參議院&quot; &quot;支持&quot; ## [25] &quot;，&quot; &quot;成為&quot; &quot;該&quot; &quot;國&quot; &quot;有史以來&quot; &quot;第一&quot; ## [31] &quot;位&quot; &quot;的&quot; &quot;華裔&quot; &quot;女性&quot; &quot;內閣&quot; &quot;成員&quot; ## [37] &quot;。&quot; ## ## [[3]] ## [1] &quot;土地公有&quot; &quot;政策&quot; &quot;?&quot; &quot;？&quot; &quot;還是&quot; &quot;土地婆&quot; ## [7] &quot;有&quot; &quot;政策&quot; &quot;。&quot; &quot;.&quot; ## ## [[4]] ## [1] &quot;…&quot; &quot; &quot; &quot;你&quot; &quot;確定&quot; &quot;嗎&quot; &quot;…&quot; &quot; &quot; &quot;不要&quot; ## [9] &quot;再&quot; &quot;騙&quot; &quot;了&quot; &quot;…&quot; &quot;…&quot; &quot;他&quot; &quot;來亂的&quot; &quot;啦&quot; ## ## [[5]] ## [1] &quot;最多&quot; &quot;容納&quot; &quot;59,000&quot; &quot;個&quot; &quot;人&quot; &quot;,&quot; &quot;或&quot; &quot;5.9萬&quot; ## [9] &quot;人&quot; &quot;,&quot; &quot;再&quot; &quot;多&quot; &quot;就&quot; &quot;不行&quot; &quot;了&quot; &quot;.&quot; ## [17] &quot;這&quot; &quot;是&quot; &quot;環評&quot; &quot;的&quot; &quot;結論&quot; &quot;.&quot; ## ## [[6]] ## [1] &quot;科長&quot; &quot;說&quot; &quot;:1,&quot; &quot;坪數&quot; &quot;對&quot; &quot;人數&quot; &quot;為&quot; &quot;1:3&quot; &quot;。&quot; &quot;2&quot; ## [11] &quot;,&quot; &quot;可以&quot; &quot;再&quot; &quot;增加&quot; &quot;。&quot; Exercise 10.1 We usually have a list of new words saved in a text file. Can you write a R function, which loads the words in the demo_data/dict-sample.txt into a named list, i.e., new_words, which can easily serve as the input for ckip$construct_dictionary() to create the python dictionary object? (Note: All weights are default to 1) new_words&lt;-loadDictionary(input = &quot;demo_data/dict-sample.txt&quot;) dictionary&lt;-ckip$construct_dictionary(new_words) # Segment texts using dictionary words_2 &lt;- ws(texts, recommend_dictionary = dictionary) words_2 ## [[1]] ## [1] &quot;傅達仁&quot; &quot;今&quot; &quot;將&quot; &quot;執行&quot; &quot;安樂死&quot; ## [6] &quot;，&quot; &quot;卻&quot; &quot;突然&quot; &quot;爆出&quot; &quot;自己&quot; ## [11] &quot;20&quot; &quot;年&quot; &quot;前&quot; &quot;遭&quot; &quot;緯來體育台&quot; ## [16] &quot;封殺&quot; &quot;，&quot; &quot;他&quot; &quot;不&quot; &quot;懂&quot; ## [21] &quot;自己&quot; &quot;哪裡&quot; &quot;得罪到&quot; &quot;電視台&quot; &quot;。&quot; ## ## [[2]] ## [1] &quot;美國&quot; &quot;參議院&quot; &quot;針對&quot; &quot;今天&quot; &quot;總統&quot; &quot;布什&quot; ## [7] &quot;所&quot; &quot;提名&quot; &quot;的&quot; &quot;勞工部長&quot; &quot;趙小蘭&quot; &quot;展開&quot; ## [13] &quot;認可&quot; &quot;聽證會&quot; &quot;，&quot; &quot;預料&quot; &quot;她&quot; &quot;將&quot; ## [19] &quot;會&quot; &quot;很&quot; &quot;順利&quot; &quot;通過&quot; &quot;參議院&quot; &quot;支持&quot; ## [25] &quot;，&quot; &quot;成為&quot; &quot;該&quot; &quot;國&quot; &quot;有史以來&quot; &quot;第一&quot; ## [31] &quot;位&quot; &quot;的&quot; &quot;華裔&quot; &quot;女性&quot; &quot;內閣&quot; &quot;成員&quot; ## [37] &quot;。&quot; ## ## [[3]] ## [1] &quot;土地公有&quot; &quot;政策&quot; &quot;?&quot; &quot;？&quot; &quot;還是&quot; &quot;土地婆&quot; ## [7] &quot;有&quot; &quot;政策&quot; &quot;。&quot; &quot;.&quot; ## ## [[4]] ## [1] &quot;…&quot; &quot; &quot; &quot;你&quot; &quot;確定&quot; &quot;嗎&quot; &quot;…&quot; &quot; &quot; &quot;不要&quot; ## [9] &quot;再&quot; &quot;騙&quot; &quot;了&quot; &quot;…&quot; &quot;…&quot; &quot;他&quot; &quot;來亂的&quot; &quot;啦&quot; ## ## [[5]] ## [1] &quot;最多&quot; &quot;容納&quot; &quot;59,000&quot; &quot;個&quot; &quot;人&quot; &quot;,&quot; &quot;或&quot; &quot;5.9萬&quot; ## [9] &quot;人&quot; &quot;,&quot; &quot;再&quot; &quot;多&quot; &quot;就&quot; &quot;不行&quot; &quot;了&quot; &quot;.&quot; ## [17] &quot;這&quot; &quot;是&quot; &quot;環評&quot; &quot;的&quot; &quot;結論&quot; &quot;.&quot; ## ## [[6]] ## [1] &quot;科長&quot; &quot;說&quot; &quot;:1,&quot; &quot;坪數&quot; &quot;對&quot; &quot;人數&quot; &quot;為&quot; &quot;1:3&quot; &quot;。&quot; &quot;2&quot; ## [11] &quot;,&quot; &quot;可以&quot; &quot;再&quot; &quot;增加&quot; &quot;。&quot; 10.10 Beyond Word Boundaries In addition to primitive word segmentation, the ckiptagger provides also the parts-of-speech tags for words and named entity recognitions for the texts. The ckiptagger follows the pipeline below for text processing. Load the models To perform these additional tasks, we need to load the necessary models (pre-trained and provided by the CKIP group) first as well. They should all have been included in the model directory you unzipped earlier (cf. ./data). # loading other necessary models system.time((pos &lt;- ckip$POS(&quot;./data&quot;))) # 詞性 6s ## user system elapsed ## 5.754 1.633 6.145 system.time((ner &lt;- ckip$NER(&quot;./data&quot;))) # 實體辨識 8s ## user system elapsed ## 5.649 1.680 6.632 POS tagging and NER # Parts-of-speech Tagging pos_words &lt;- pos(words_1) pos_words ## [[1]] ## [1] &quot;Nb&quot; &quot;Nd&quot; &quot;D&quot; &quot;VC&quot; ## [5] &quot;Na&quot; &quot;COMMACATEGORY&quot; &quot;D&quot; &quot;D&quot; ## [9] &quot;VJ&quot; &quot;Nh&quot; &quot;Neu&quot; &quot;Nf&quot; ## [13] &quot;Ng&quot; &quot;P&quot; &quot;Nc&quot; &quot;VC&quot; ## [17] &quot;COMMACATEGORY&quot; &quot;Nh&quot; &quot;D&quot; &quot;VK&quot; ## [21] &quot;Nh&quot; &quot;Ncd&quot; &quot;VJ&quot; &quot;Nc&quot; ## [25] &quot;PERIODCATEGORY&quot; ## ## [[2]] ## [1] &quot;Nc&quot; &quot;Nc&quot; &quot;P&quot; &quot;Nd&quot; ## [5] &quot;Na&quot; &quot;Nb&quot; &quot;D&quot; &quot;VC&quot; ## [9] &quot;DE&quot; &quot;Na&quot; &quot;Nb&quot; &quot;VC&quot; ## [13] &quot;VC&quot; &quot;Na&quot; &quot;COMMACATEGORY&quot; &quot;VE&quot; ## [17] &quot;Nh&quot; &quot;D&quot; &quot;D&quot; &quot;Dfa&quot; ## [21] &quot;VH&quot; &quot;VC&quot; &quot;Nc&quot; &quot;VC&quot; ## [25] &quot;COMMACATEGORY&quot; &quot;VG&quot; &quot;Nes&quot; &quot;Nc&quot; ## [29] &quot;D&quot; &quot;Neu&quot; &quot;Nf&quot; &quot;DE&quot; ## [33] &quot;Na&quot; &quot;Na&quot; &quot;Na&quot; &quot;Na&quot; ## [37] &quot;PERIODCATEGORY&quot; ## ## [[3]] ## [1] &quot;VH&quot; &quot;Na&quot; &quot;QUESTIONCATEGORY&quot; &quot;QUESTIONCATEGORY&quot; ## [5] &quot;Caa&quot; &quot;Nb&quot; &quot;V_2&quot; &quot;Na&quot; ## [9] &quot;PERIODCATEGORY&quot; &quot;PERIODCATEGORY&quot; ## ## [[4]] ## [1] &quot;ETCCATEGORY&quot; &quot;WHITESPACE&quot; &quot;Nh&quot; &quot;VK&quot; &quot;T&quot; ## [6] &quot;ETCCATEGORY&quot; &quot;WHITESPACE&quot; &quot;D&quot; &quot;D&quot; &quot;VC&quot; ## [11] &quot;Di&quot; &quot;ETCCATEGORY&quot; &quot;ETCCATEGORY&quot; &quot;Nh&quot; &quot;VA&quot; ## [16] &quot;T&quot; ## ## [[5]] ## [1] &quot;VH&quot; &quot;VJ&quot; &quot;Neu&quot; &quot;Nf&quot; ## [5] &quot;Na&quot; &quot;COMMACATEGORY&quot; &quot;Caa&quot; &quot;Neu&quot; ## [9] &quot;Na&quot; &quot;COMMACATEGORY&quot; &quot;D&quot; &quot;D&quot; ## [13] &quot;D&quot; &quot;VH&quot; &quot;T&quot; &quot;PERIODCATEGORY&quot; ## [17] &quot;Nep&quot; &quot;SHI&quot; &quot;Na&quot; &quot;DE&quot; ## [21] &quot;Na&quot; &quot;PERIODCATEGORY&quot; ## ## [[6]] ## [1] &quot;Na&quot; &quot;VE&quot; &quot;Neu&quot; &quot;Na&quot; ## [5] &quot;P&quot; &quot;Na&quot; &quot;VG&quot; &quot;Neu&quot; ## [9] &quot;PERIODCATEGORY&quot; &quot;Neu&quot; &quot;COMMACATEGORY&quot; &quot;D&quot; ## [13] &quot;D&quot; &quot;VHC&quot; &quot;PERIODCATEGORY&quot; # Named Entity Recognition ner &lt;- ner(words_1, pos_words) ner ## [[1]] ## {(23, 28, &#39;ORG&#39;, &#39;緯來體育台&#39;), (0, 3, &#39;PERSON&#39;, &#39;傅達仁&#39;), (18, 22, &#39;DATE&#39;, &#39;20年前&#39;)} ## ## [[2]] ## {(7, 9, &#39;DATE&#39;, &#39;今天&#39;), (42, 45, &#39;ORG&#39;, &#39;參議院&#39;), (21, 24, &#39;PERSON&#39;, &#39;趙小蘭&#39;), (56, 58, &#39;ORDINAL&#39;, &#39;第一&#39;), (11, 13, &#39;PERSON&#39;, &#39;布什&#39;), (2, 5, &#39;ORG&#39;, &#39;參議院&#39;), (0, 2, &#39;GPE&#39;, &#39;美國&#39;), (60, 62, &#39;NORP&#39;, &#39;華裔&#39;), (17, 21, &#39;ORG&#39;, &#39;勞工部長&#39;)} ## ## [[3]] ## {(10, 13, &#39;PERSON&#39;, &#39;土地婆&#39;)} ## ## [[4]] ## set() ## ## [[5]] ## {(4, 10, &#39;CARDINAL&#39;, &#39;59,000&#39;), (14, 18, &#39;CARDINAL&#39;, &#39;5.9萬&#39;)} ## ## [[6]] ## {(4, 6, &#39;CARDINAL&#39;, &#39;1,&#39;), (16, 17, &#39;CARDINAL&#39;, &#39;2&#39;), (12, 13, &#39;CARDINAL&#39;, &#39;1&#39;), (14, 15, &#39;CARDINAL&#39;, &#39;3&#39;)} 10.11 Tidy Up the Results We can tidy up results provided by ckiptagger and create a word-based tidy structure of our data: word_df &lt;- data.frame(text_id = mapply(rep, c(1:length(texts)), sapply(words_1, length)) %&gt;% unlist, words = do.call(c, words_1), pos = do.call(c, pos_words)) word_df Exercise 10.2 With a word-based tidy structure of the corpus, it is easy to convert it into a text-based one with both the information of word boundaries and parts-of-speech tag. Please convert the above word_df into a text-based data frame, as shown below. Exercise 10.3 How to tidy up the results of ner so that we can include the recognized named entities in the same word-based data frame word_df? You may need to convert the output of ner from ckiptagger into a data frame like this: And figure out a way to add the annotations of named entities in the word-based data frame, word_df, by including another column, as shown below: The above result data frame makes use of the IOB format (short for inside, outside, beginning) for the annotations of the named entities. It is a common tagging format for tagging (multiword) tokens in a chunking task in computational linguistics (e.g., NP-chunking, named entitity, semantic roles). The B- prefix before a tag indicates that the tag is the beginning of a chunk. The I- prefix before a tag indicates that the tag is inside a chunk. The O tag indicates that a token belongs to no chunk (i.e., outside of all relevant chunks). "]
]
