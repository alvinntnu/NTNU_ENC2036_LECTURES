[
["xml.html", "Chapter 11 XML 11.1 BNC Spoken 2014 11.2 Process the Whole Directory of BNC2014 Sample 11.3 Metadata 11.4 BNC2014 for Socialinguistic Variation 11.5 Word Frequency vs. Gender 11.6 Degree ADV + ADJ", " Chapter 11 XML library(tidyverse) library(readtext) library(rvest) library(tidytext) library(quanteda) This chapter shows you how to process the recently released BNC 2014, which is by far the largest representative collection of spoken English collected in UK. For the purpose of our in-class tutorials, I have included a small sample of the BNC2014 in our demo_data. However, the whole dataset is now available via the official website: British National Corpus 2014. Please sign up for the complete access to the corpus if you need this corpus for your own research. 11.1 BNC Spoken 2014 XML is similar to HTML. Before you process the data, you need to understand the structure of the XML tags in the files. Other than that, the steps are pretty much similar to what we have done before. First, we read the XML using read_html(): # read one file at a time corp_bnc&lt;-read_html(&quot;demo_data/corp-bnc-spoken2014-sample/S2A5-tgd.xml&quot;) Now it is intuitive that our next step is to extract all utterances (with the tag of &lt;u&gt;...&lt;/u&gt;) in the XML file. So you may want to do the following: corp_bnc %&gt;% html_nodes(xpath = &quot;//u&quot;) %&gt;% html_text %&gt;% head ## [1] &quot;\\r\\nanhourlaterhopeshestaysdownratherlate&quot; ## [2] &quot;\\r\\nwellshehadthosetwohoursearlier&quot; ## [3] &quot;\\r\\nyeahIknowbutthat&#39;swhywe&#39;reanhourlateisn&#39;tit?mmI&#39;mtirednow&quot; ## [4] &quot;\\r\\n&quot; ## [5] &quot;\\r\\ndidyoutext--ANONnameM&quot; ## [6] &quot;\\r\\nyeahyeahhewrotebacknobotherlad&quot; See the problem? Using the above method, you lose the word boundary information from the corpus. What if you do the following? corp_bnc %&gt;% html_nodes(xpath = &quot;//w&quot;) %&gt;% html_text %&gt;% head(20) ## [1] &quot;an&quot; &quot;hour&quot; &quot;later&quot; &quot;hope&quot; &quot;she&quot; &quot;stays&quot; &quot;down&quot; ## [8] &quot;rather&quot; &quot;late&quot; &quot;well&quot; &quot;she&quot; &quot;had&quot; &quot;those&quot; &quot;two&quot; ## [15] &quot;hours&quot; &quot;earlier&quot; &quot;yeah&quot; &quot;I&quot; &quot;know&quot; &quot;but&quot; At the first sight, probably it seems that we have solved the problem but we don’t. There are even more problems created: Our second method does not extract non-word tokens within each utterance (e.g., &lt;pause .../&gt;, &lt;vocal .../&gt;) Our second method loses the utterance information (i.e., we don’t know which utterance each word belongs to) So we cannot extract &lt;u&gt; elements all at once; nor can we extract all &lt;w&gt; elements all at once. Probably we need to process each &lt;u&gt; node one at a time. First, let’s get all the &lt;u&gt; nodes. node_u &lt;- corp_bnc %&gt;% html_nodes(xpath=&quot;//u&quot;) node_u[[1]] ## {html_node} ## &lt;u n=&quot;1&quot; who=&quot;S0024&quot; trans=&quot;nonoverlap&quot; whoconfidence=&quot;high&quot;&gt; ## [1] &lt;w pos=&quot;AT1&quot; lemma=&quot;a&quot; class=&quot;ART&quot; usas=&quot;Z5&quot;&gt;an&lt;/w&gt; ## [2] &lt;w pos=&quot;NNT1&quot; lemma=&quot;hour&quot; class=&quot;SUBST&quot; usas=&quot;T1:3&quot;&gt;hour&lt;/w&gt; ## [3] &lt;w pos=&quot;RRR&quot; lemma=&quot;later&quot; class=&quot;ADV&quot; usas=&quot;T4&quot;&gt;later&lt;/w&gt; ## [4] &lt;pause dur=&quot;short&quot;&gt;&lt;/pause&gt; ## [5] &lt;w pos=&quot;VV0&quot; lemma=&quot;hope&quot; class=&quot;VERB&quot; usas=&quot;X2:6&quot;&gt;hope&lt;/w&gt; ## [6] &lt;w pos=&quot;PPHS1&quot; lemma=&quot;she&quot; class=&quot;PRON&quot; usas=&quot;Z8&quot;&gt;she&lt;/w&gt; ## [7] &lt;w pos=&quot;VVZ&quot; lemma=&quot;stay&quot; class=&quot;VERB&quot; usas=&quot;M8&quot;&gt;stays&lt;/w&gt; ## [8] &lt;w pos=&quot;RP&quot; lemma=&quot;down&quot; class=&quot;ADV&quot; usas=&quot;Z5&quot;&gt;down&lt;/w&gt; ## [9] &lt;pause dur=&quot;short&quot;&gt;&lt;/pause&gt; ## [10] &lt;w pos=&quot;RG&quot; lemma=&quot;rather&quot; class=&quot;ADV&quot; usas=&quot;A13:5&quot;&gt;rather&lt;/w&gt; ## [11] &lt;w pos=&quot;JJ&quot; lemma=&quot;late&quot; class=&quot;ADJ&quot; usas=&quot;T4&quot;&gt;late&lt;/w&gt; Take the first node in the XML document for example, each utterance node includes words as well as non-word tokens (i.e., paralinguistic annotations &lt;pause ...&gt;&lt;/pause&gt;). We can retrieve: words in an utterance lemma forms of all words in the utterance pos tags of all words in the utterance (BNC2014 uses UCREL CLAWS6 Tagset) paralinguistic tags in the utterance node_u[[1]] %&gt;% html_children %&gt;% html_text ## [1] &quot;an&quot; &quot;hour&quot; &quot;later&quot; &quot;&quot; &quot;hope&quot; &quot;she&quot; &quot;stays&quot; &quot;down&quot; ## [9] &quot;&quot; &quot;rather&quot; &quot;late&quot; node_u[[1]] %&gt;% html_children %&gt;% html_attr(&quot;pos&quot;) ## [1] &quot;AT1&quot; &quot;NNT1&quot; &quot;RRR&quot; NA &quot;VV0&quot; &quot;PPHS1&quot; &quot;VVZ&quot; &quot;RP&quot; NA ## [10] &quot;RG&quot; &quot;JJ&quot; node_u[[1]] %&gt;% html_children %&gt;% html_attr(&quot;lemma&quot;) ## [1] &quot;a&quot; &quot;hour&quot; &quot;later&quot; NA &quot;hope&quot; &quot;she&quot; &quot;stay&quot; &quot;down&quot; ## [9] NA &quot;rather&quot; &quot;late&quot; Exercise 11.1 Please come up with a way to extract both word and non-word tokens from each utterance. Ideally, the resulting data frame should consist of rows being the utterances, and columns including the attributes of each autterances. Most importantly, the data frame should record not only the strings of the utterance but at the same time for the word tokens, it should preserve the token-level annotation of word part-of-speech tags (see the utterance column in the table below). A sample utterance-based data frame is provided below. 11.2 Process the Whole Directory of BNC2014 Sample 11.2.1 Define Function In Section 11.1, if you have figured how to extract utterances as well as token-based information from the xml file, you can easily wrap the whole procedure as one function. With this function, we can perform the same procedure to all the xml files of the BNC2014. For example, let’s assume that we have defined a function: read_xml_bnc2014 &lt;- function(xml){ ... } This function takes one xml file as an argument and return a data frame, consisting of utterances and other relevant token-level information from the xml. read_xml_bnc2014(xmlfile = &quot;demo_data/corp-bnc-spoken2014-sample/S2A5-tgd.xml&quot;) Exercise 11.2 Now your job is to write this function, read_xml_BNC2014(xml = &quot;&quot;). 11.2.2 Process the all files in the Directory Now we utilize the self-defined function, read_xml_BNC2014(), and process all xml files in the demo_data/corp-bnc-spoken2014-sample/. Also, we combine the individual data.frame returned from each xml into a bigger one, i.e., corp_bnc_df: s.t &lt;- Sys.time() bnc_flist &lt;- dir(&quot;demo_data/corp-bnc-spoken2014-sample/&quot;,full.names = T) corp_bnc_df &lt;- map(bnc_flist, function(x) read_xml_bnc2014(x)) %&gt;% # map `read_xml_bnc2014()` to each xml in the dir do.call(rbind, .) # rbind all individual DFs Sys.time()-s.t ## Time difference of 56.67211 secs It takes about one and half minute to process the sample directory. You may store this corp_bnc_df data frame output for later use so that you don’t have to process the XML files every time you work with BNC2014. write_csv(corp_bnc_df, &quot;demo_data/corp_bnc_df.csv&quot;,col_names = T) 11.3 Metadata The best thing about BNC2014 is its rich demographic information relating to the settings and speakers of the conversations collected. The whole corpus comes with two metadata sets: bnc2014spoken-textdata.tsv: metadata for each text transcript bnc2014spoken-speakerdata.tsv: metadata for each speaker ID These two metadata sets allow us to get more information about each transcript as well as the speakers in those transcripts. 11.3.1 Text Metadata There are two files that are relevant to the text metadata: bnc2014spoken-textdata.tsv: This file includes the header/metadata information of each text file metadata-fields-text.txt: This file includes the column names/meanings of the previous text metadata tsv, i.e., bnc2014spoken-textdata.tsv. bnc_text_meta &lt;- read_tsv(&quot;demo_data/corp-bnc-spoken2014-metadata/bnc2014spoken-textdata.tsv&quot;, col_names = FALSE) bnc_text_meta bnc_text_meta_names &lt;-read_tsv(&quot;demo_data/corp-bnc-spoken2014-metadata/metadata-fields-text.txt&quot;, skip =2, col_names = F) bnc_text_meta_names names(bnc_text_meta) &lt;- c(&quot;textid&quot;, bnc_text_meta_names$X2) bnc_text_meta 11.3.2 Speaker Metadata There are two files that are relevant to the speaker metadata: bnc2014spoken-speakerdata.tsv: This file includes the demographic information of each speaker metadata-fields-speaker.txt: This file includes the column names/meanings of the previous speaker metadata tsv, i.e., bnc2014spoken-speakerdata.tsv. bnc_sp_meta &lt;- read_tsv(&quot;demo_data/corp-bnc-spoken2014-metadata/bnc2014spoken-speakerdata.tsv&quot;, col_names = F) bnc_sp_meta bnc_sp_meta_names &lt;- read_tsv(&quot;demo_data/corp-bnc-spoken2014-metadata/metadata-fields-speaker.txt&quot;, skip = 3, col_names = F) bnc_sp_meta_names names(bnc_sp_meta) &lt;- c(&quot;spid&quot;, bnc_sp_meta_names$X2) bnc_sp_meta 11.4 BNC2014 for Socialinguistic Variation Now with both the text-level and speker-level metadata, bnc_text_meta and bnc_sp_meta, we can easily connect the utterances to speaker and text profiles using their unique ID’s. BNC2014 was born for the study of socio-linguistic variation. Here I would like to show you some naitve examples, but you should get the ideas and the potentials of BNC2014. 11.5 Word Frequency vs. Gender Now we are ready to explore the gender differences in language. 11.5.1 Preprocessing To begin with, there are some utterances with no words at all. We probably like to remove these tokens. #corp_bnc_df &lt;- read_csv(&quot;demo_data/corp_bnc_df.csv&quot;) corp_bnc_df &lt;- corp_bnc_df %&gt;% filter(!is.na(utterance)) corp_bnc_df 11.5.2 Target Structures Let’s assume that we like to know which adjectives are most frequently used by men and women. corp_bnc_verb_gender &lt;- corp_bnc_df %&gt;% filter(str_detect(utterance, &quot;_(JJ)|(JJR)|(JJT)&quot;)) %&gt;% # extract utterances with at least one adj left_join(bnc_sp_meta, by = c(&quot;who&quot;=&quot;spid&quot;)) # attach SP metadata to the data frame corp_bnc_verb_gender 11.5.3 Analysis After we extract utterances with our target structures, we tokenize the utterances and create frequency lists of target structures, i.e., the adjectives. ## Problems ### Use own tokenization function ### Default tokenization increase the number of tokens quite a bit word_by_gender &lt;- corp_bnc_verb_gender %&gt;% unnest_tokens(word, utterance, to_lower = F, token = function(x) strsplit(x, split = &quot;\\\\s&quot;)) %&gt;% # tokenize utterance into words filter(str_detect(word, &quot;[^_]+_(JJ)|(JJR)|(JJT)&quot;)) %&gt;% # include adj only mutate(word = str_replace(word, &quot;_(JJ)|(JJR)|(JJT)&quot;,&quot;&quot;)) %&gt;% # remove pos tags count(gender, word) word_by_gender_top200 &lt;- word_by_gender %&gt;% group_by(gender) %&gt;% top_n(200,n) %&gt;% ungroup word_by_gender_top200 Female wordcloud require(wordcloud2) word_by_gender_top200 %&gt;% filter(gender==&quot;F&quot;) %&gt;% select(word, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) Male wordcloud word_by_gender_top200 %&gt;% filter(gender==&quot;M&quot;) %&gt;% select(word, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) Exercise 11.3 Which adjectives are more often used by male and female speakers? This should be a statistical problem. We can in fact extend our keyword analysis (cf. Chapter 6) to this question. Please use the statistics of keyword analysis to find out the top 20 adjectives that are strongly attracted to female and male speakers according to G2 statistics. Please include in the analysis words whose frequencies &gt;= 20 in the corpus. Also, please note the problem of the NaN values out of the log(). 11.6 Degree ADV + ADJ In this example, I would like to look at the adjectives that are emphasized in conversations and examine how these emphatic adjective may differ in speakers of different genders. corp_bnc_pattern_gender &lt;- corp_bnc_df %&gt;% filter(str_detect(utterance, &quot;[^_]+_RG [^_]+_JJ&quot;)) %&gt;% # extract utterances with at least one verb left_join(bnc_sp_meta, by = c(&quot;who&quot;=&quot;spid&quot;)) # attach SP metadata to the data frame pattern_by_gender &lt;- corp_bnc_pattern_gender %&gt;% unnest_tokens(pattern, utterance, to_lower = F, token = function(x) str_extract_all(x, &quot;[^_ ]+_RG [^_ ]+_JJ &quot;)) %&gt;% mutate(pattern = pattern %&gt;% str_trim %&gt;% str_replace_all(&quot;_[^_ ]+&quot;,&quot;&quot;)) %&gt;% # remove pos tags separate(pattern, into = c(&quot;ADV&quot;,&quot;ADJ&quot;), sep = &quot;\\\\s&quot;) %&gt;% count(gender, ADJ) %&gt;% group_by(gender) %&gt;% top_n(100,n) %&gt;% ungroup pattern_by_gender pattern_by_gender %&gt;% filter(gender==&quot;M&quot;) %&gt;% select(ADJ, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) pattern_by_gender %&gt;% filter(gender==&quot;M&quot;) %&gt;% select(ADJ, n) %&gt;% wordcloud2(size = 2, minRotation = -pi/2, maxRotation = -pi/2) Exercise 11.4 Please analyze the verbs that co-occur with the first-person pronoun I in BNC2014 in terms of speakers of different genders. Please create a frequency list of verbs that follow the first person pronoun I in demo_data/corp-bnc-spoken2014-sample. Verbs are defined as any words whose POS tag starts with VV. Please create the word clouds of the top 100 verbs for male and female speakers. Exercise 11.5 Please analyze the recurrent trigrams used by male and female speakers by showing the top 20 trigrams used by males and females respectively ranked according to their dispersions. Dispersion of trigrams is defined as the number of texts where the trigram is observed. "]
]
